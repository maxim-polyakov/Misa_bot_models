{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:27.069373601Z",
     "start_time": "2023-06-02T19:30:25.595129024Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "SELECT_EMOTIONS = str('(select text, emotionid  FROM train_sets.all_set_weather ORDER BY random() LIMIT 3000) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_none ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_thanks ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_hi ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_business ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_trash ORDER BY random() LIMIT 600) ')\n",
    "\n",
    "conn_remote = psycopg2.connect(\n",
    "    'postgres://postgres:gaTResKPJX25@ep-round-paper-091468.us-east-2.aws.neon.tech/SistersMemory')\n",
    "\n",
    "target = 'emotionid'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:31.129860079Z",
     "start_time": "2023-06-02T19:30:26.996492445Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "## Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð±Ð°Ð·Ðµ Ð»ÐµÐ¼Ð°Ð½Ð°Ñ‚Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ñ‹\n",
    "class CommonPreprocessing:\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_text(cls, text):\n",
    "        # Ð¿Ñ€ÐµÐ´Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸Ðº Ð¿Ñ€Ð¸Ð²Ð¾Ð´Ð¸Ñ‚ ÑÐ»Ð¾Ð²Ð° Ð² Ð½Ð°Ñ‡Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ„Ð¾Ñ€Ð¼Ñƒ. Ð”Ð°Ð½Ð½Ñ‹Ðµ Ð² Ð±Ð°Ð·Ðµ Ð½Ð°Ñ…Ð¾Ð´ÑÑ‚ÑÑ Ð² Ð»ÐµÐ¼Ð°Ð½Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ð¸ Ð¿ÐµÑ€ÐµÐ´ Ð¿Ð¾Ð´Ð°Ñ‡ÐµÐ¹ Ð½Ð° Ñ‚Ð¾ÐºÐµÐ½Ð¸Ð·Ð°Ñ†Ð¸ÑŽ Ð² Ð¿Ñ€ÐµÐ´Ð¸ÐºÑ‚ ÑÐ»Ð¾Ð²Ð¾ Ñ‚Ð¾Ð¶Ðµ Ð»ÐµÐ¼Ð°Ð½Ð°Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ÑÑ\n",
    "        #\n",
    "        try:\n",
    "            tokens = str(text)\n",
    "            tokens = Mystem().lemmatize(text.lower())\n",
    "            tokens = [token for token in tokens if token not in stopwords.words('russian')\n",
    "                      and token != ' '\n",
    "                      and token.strip() not in punctuation]\n",
    "            tokens = [\n",
    "                token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "            text = ' '.join(tokens).rstrip('\\n')\n",
    "            pattern3 = r'[\\d]'\n",
    "            pattern2 = '[.]'\n",
    "            text = re.sub(pattern3, '', text)\n",
    "            text = re.sub(pattern2, '', text)\n",
    "            text = re.sub('  ', ' ', text)\n",
    "            return text\n",
    "        except:\n",
    "            return 'The exception is in CommonPreprocessing.preprocess_text'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:31.164349509Z",
     "start_time": "2023-06-02T19:30:31.137273982Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3877/3183445660.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0             ÐºÐ»Ð¸Ð¼Ð°Ñ‚ Ð¸Ñ€Ð»Ð°Ð½Ð´Ð¸Ñ Ð¸Ð·ÑƒÐ¼Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð³Ð¾Ð´Ð° Ð³Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ\n1                                                   Ñ‚ÑƒÐ¼Ð°Ð½\n2                                               Ð¿Ñ€Ð¾Ñ…Ð»Ð°Ð´Ð½Ð¾\n4                                                   Ð´Ð¾Ð¶Ð´ÑŒ\n6       Ð¿Ð°ÑÐ¼ÑƒÑ€Ð½Ð¾ Ð½ÐµÐ±Ð¾Ð»ÑŒÑˆÐ¾Ð¹ ÑÐ½ÐµÐ³ Ñ‚ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð° Ð´Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ²Ðµ...\n                              ...                        \n5696                                                Ð³Ð½Ð¸Ð´Ð°\n5699                                               Ð³Ð¾Ð²ÑÐ³Ð°\n5703                    Ð¶Ð¸Ð·Ð½ÑŒ Ð½Ð°ÑÑ€Ð°Ñ‚ÑŒ Ð±ÐµÐ³Ð°Ñ‚ÑŒ Ð±Ñ‹ÑÑ‚Ñ€Ð¾ ÑƒÐ¼ÐµÑ‚ÑŒ\n5704                          Ð±Ð¸Ñ‚ÑŒÑÑ Ð·Ð°ÐºÐ»Ð°Ð´ Ð·Ð°Ñ‡Ð¸Ð½Ð°Ñ‚ÑŒ ÑÐ¿Ð¾Ñ€\n5715                                          ÑÑƒÑ‡ÐºÐ° ÐµÐ±Ð°Ñ‚ÑŒ\nName: text, Length: 1321, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n",
    "train.text = train.text.astype(str)\n",
    "train = train.drop_duplicates()\n",
    "train.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:32.840127957Z",
     "start_time": "2023-06-02T19:30:31.144889474Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train['text'], train[target], test_size=0.3, random_state=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:32.861773144Z",
     "start_time": "2023-06-02T19:30:32.841393781Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (924,)\n",
      "Shape of Validation  (397,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of train', X_train.shape)\n",
    "print('Shape of Validation ', X_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:32.862734103Z",
     "start_time": "2023-06-02T19:30:32.852703406Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "tokenizer = CountVectorizer()\n",
    "\n",
    "X_train = tokenizer.fit_transform(X_train).toarray()\n",
    "\n",
    "X_val = tokenizer.transform(X_val).toarray()\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, Y_train)\n",
    "\n",
    "with open('models/multy/NaiveBayes/0_nbemotionsmodel.pickle', 'wb') as handle:\n",
    "    p.dump(tokenizer, handle,\n",
    "        protocol=p.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('tokenizers/multy/NaiveBayes/0_nbemotionstokenizer.pickle', 'wb') as handle:\n",
    "    p.dump(nb_model, handle,\n",
    "        protocol=p.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:33.184554730Z",
     "start_time": "2023-06-02T19:30:32.857014443Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "EMOTIONSMAPA = {0: 'ðŸ˜ž', 1: 'ðŸ¤¬', 2: 'ðŸ˜¨', 3: 'ðŸ˜Š', 4: 'â¤', 5: 'ðŸ˜³', 6: ''}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:33.255371400Z",
     "start_time": "2023-06-02T19:30:33.000761895Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "\n",
    "    @classmethod\n",
    "    def predict(cls, inpt, tmap, model, tokenizer):\n",
    "#\n",
    "#\n",
    "        with open(model, 'rb') as handle:\n",
    "            model = p.load(handle)\n",
    "\n",
    "        inn = []\n",
    "        pr = CommonPreprocessing()\n",
    "        for i in inpt:\n",
    "            inn.append(pr.preprocess_text(i))\n",
    "\n",
    "        with open(tokenizer, 'rb') as handle:\n",
    "            tokenizer = p.load(handle)\n",
    "            tokenized_inpt = tokenizer.transform(inn).toarray()\n",
    "\n",
    "        cls.score = model.predict_proba(tokenized_inpt)\n",
    "\n",
    "        return(tmap[cls.score.argmax(axis=-1)[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:33.256209400Z",
     "start_time": "2023-06-02T19:30:33.015007448Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "model = 'models/multy/NaiveBayes/0_nbemotionsmodel.pickle'\n",
    "tokenizer = 'tokenizers/multy/NaiveBayes/0_nbemotionstokenizer.pickle'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:33.256623185Z",
     "start_time": "2023-06-02T19:30:33.058411618Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m nb \u001B[38;5;241m=\u001B[39m NaiveBayes()\n\u001B[0;32m----> 2\u001B[0m emotion \u001B[38;5;241m=\u001B[39m \u001B[43mnb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mÐ¿Ñ€Ð¸Ð²ÐµÑ‚\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEMOTIONSMAPA\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m emotion\n",
      "Cell \u001B[0;32mIn[9], line 17\u001B[0m, in \u001B[0;36mNaiveBayes.predict\u001B[0;34m(cls, inpt, tmap, model, tokenizer)\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(tokenizer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m handle:\n\u001B[1;32m     16\u001B[0m     tokenizer \u001B[38;5;241m=\u001B[39m p\u001B[38;5;241m.\u001B[39mload(handle)\n\u001B[0;32m---> 17\u001B[0m     tokenized_inpt \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m(inn)\u001B[38;5;241m.\u001B[39mtoarray()\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mscore \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict_proba(tokenized_inpt)\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m(tmap[\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mscore\u001B[38;5;241m.\u001B[39margmax(axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]])\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'MultinomialNB' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayes()\n",
    "emotion = nb.predict('Ð¿Ñ€Ð¸Ð²ÐµÑ‚', EMOTIONSMAPA, model, tokenizer)\n",
    "emotion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-02T19:30:38.357493927Z",
     "start_time": "2023-06-02T19:30:33.058615796Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
