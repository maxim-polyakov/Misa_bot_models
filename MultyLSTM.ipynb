{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pickle as p\n",
    "import tensorflow as tensorflow\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer as token\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "EMBEDDING_VECTOR_LENGTH = 33"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:28.636468190Z",
     "start_time": "2023-06-04T12:07:28.538317517Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    TOP_K = 20000\n",
    "    MAX_SEQUENCE_LENGTH = 33\n",
    "\n",
    "    def __init__(self, train_texts):\n",
    "# токенизатор собственно\n",
    "#\n",
    "        self.train_texts = train_texts\n",
    "        self.tokenizer = token(num_words=self.TOP_K)\n",
    "\n",
    "    def train_tokenize(self):\n",
    "#\n",
    "#\n",
    "        max_length = len(max(self.train_texts, key=len))\n",
    "        self.max_length = min(max_length, self.MAX_SEQUENCE_LENGTH)\n",
    "        self.tokenizer.fit_on_texts(self.train_texts)\n",
    "\n",
    "    def vectorize_input(self, tweets):\n",
    "#\n",
    "#\n",
    "        tweets = self.tokenizer.texts_to_sequences(tweets)\n",
    "        tweets = pad_sequences(tweets, maxlen=self.max_length, truncating='post', padding='post')\n",
    "        return tweets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:28.682612128Z",
     "start_time": "2023-06-04T12:07:28.591232682Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "SELECT_EMOTIONS = str('(select text, emotionid  FROM train_sets.all_set_weather ORDER BY random() LIMIT 3000) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_none ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_thanks ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_hi ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_business ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_trash ORDER BY random() LIMIT 600) ')\n",
    "\n",
    "conn_remote = psycopg2.connect(\n",
    "    'postgres://postgres:gaTResKPJX25@ep-round-paper-091468.us-east-2.aws.neon.tech/SistersMemory')\n",
    "\n",
    "target = 'emotionid'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:29.640093028Z",
     "start_time": "2023-06-04T12:07:28.591559580Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21679/178288445.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0                                               прохладно\n1          ясно осадки температура давлениеветер западный\n2       плохой погода бывать бывать неподходящий костю...\n3       метеорология научный обоснование неверный прогноз\n4       миннесота бывать холодный ночь приходиться над...\n                              ...                        \n5712                               выебываешся ебаный рот\n5713                                             херовина\n5714               хуй кушать блять че звонить чебуречный\n5715                                        спидозный пес\n5716                                            изговнять\nName: text, Length: 5717, dtype: object"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n",
    "train.text = train.text.astype(str)\n",
    "train.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:31.308328388Z",
     "start_time": "2023-06-04T12:07:29.626598332Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  emotionid\n",
      "0                                             прохладно          6\n",
      "1        ясно осадки температура давлениеветер западный          6\n",
      "2     плохой погода бывать бывать неподходящий костю...          6\n",
      "3     метеорология научный обоснование неверный прогноз          6\n",
      "4     миннесота бывать холодный ночь приходиться над...          6\n",
      "...                                                 ...        ...\n",
      "5705                                   ебать заваль бля          1\n",
      "5707                            клизма знать свой место          1\n",
      "5708                             бабайка детство пугать          1\n",
      "5713                                           херовина          1\n",
      "5715                                      спидозный пес          1\n",
      "\n",
      "[1328 rows x 2 columns]\n",
      "Shape of train (1062, 2)\n",
      "Shape of Validation  (266, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train])\n",
    "train = df[~df[target].isna()]\n",
    "train[target] = train[target].astype(int)\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "print(train)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train, train[target], test_size=0.2, random_state=64)\n",
    "print('Shape of train', X_train.shape)\n",
    "print('Shape of Validation ', X_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:31.309274282Z",
     "start_time": "2023-06-04T12:07:31.239716646Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(train_texts=X_train['text'])\n",
    "tokenizer.train_tokenize()\n",
    "tokenized_X_train = tokenizer.vectorize_input(X_train['text'])\n",
    "tokenized_X_val = tokenizer.vectorize_input(X_val['text'])\n",
    "y_trainmatrix = tensorflow.keras.utils.to_categorical(y_train, 7)\n",
    "y_valmatrix = tensorflow.keras.utils.to_categorical(y_val, 7)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:31.309776808Z",
     "start_time": "2023-06-04T12:07:31.240061472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "optimzer = Adam(learning_rate=0.005)\n",
    "model.add(Embedding(len(tokenizer.tokenizer.word_index) + 1,\n",
    "                    EMBEDDING_VECTOR_LENGTH,\n",
    "                    input_length=tokenizer.MAX_SEQUENCE_LENGTH,\n",
    "                    trainable=True))\n",
    "model.add(Bidirectional(LSTM(256, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.compile(optimizer=optimzer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:07:32.413425304Z",
     "start_time": "2023-06-04T12:07:31.311527909Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "21/21 - 32s - loss: 1.6052 - accuracy: 0.3945 - val_loss: 1.2392 - val_accuracy: 0.4286 - 32s/epoch - 2s/step\n",
      "Epoch 2/20\n",
      "21/21 - 15s - loss: 0.9877 - accuracy: 0.6262 - val_loss: 0.9198 - val_accuracy: 0.6992 - 15s/epoch - 722ms/step\n",
      "Epoch 3/20\n",
      "21/21 - 14s - loss: 0.6038 - accuracy: 0.8079 - val_loss: 0.9731 - val_accuracy: 0.7068 - 14s/epoch - 682ms/step\n",
      "Epoch 4/20\n",
      "21/21 - 13s - loss: 0.5512 - accuracy: 0.8220 - val_loss: 1.0219 - val_accuracy: 0.7068 - 13s/epoch - 606ms/step\n",
      "Epoch 5/20\n",
      "21/21 - 13s - loss: 0.3601 - accuracy: 0.8804 - val_loss: 1.7156 - val_accuracy: 0.6955 - 13s/epoch - 597ms/step\n",
      "Epoch 6/20\n",
      "21/21 - 13s - loss: 0.3420 - accuracy: 0.8898 - val_loss: 1.0488 - val_accuracy: 0.7594 - 13s/epoch - 617ms/step\n",
      "Epoch 7/20\n",
      "21/21 - 13s - loss: 0.2387 - accuracy: 0.9237 - val_loss: 1.2973 - val_accuracy: 0.7481 - 13s/epoch - 635ms/step\n",
      "Epoch 8/20\n",
      "21/21 - 15s - loss: 0.1803 - accuracy: 0.9473 - val_loss: 1.2151 - val_accuracy: 0.7632 - 15s/epoch - 719ms/step\n",
      "Epoch 9/20\n",
      "21/21 - 15s - loss: 0.1225 - accuracy: 0.9642 - val_loss: 1.4801 - val_accuracy: 0.7218 - 15s/epoch - 720ms/step\n",
      "Epoch 10/20\n",
      "21/21 - 16s - loss: 0.1356 - accuracy: 0.9661 - val_loss: 1.3307 - val_accuracy: 0.7444 - 16s/epoch - 754ms/step\n",
      "Epoch 11/20\n",
      "21/21 - 16s - loss: 0.0982 - accuracy: 0.9708 - val_loss: 1.4751 - val_accuracy: 0.7707 - 16s/epoch - 771ms/step\n",
      "Epoch 12/20\n",
      "21/21 - 16s - loss: 0.1009 - accuracy: 0.9661 - val_loss: 1.5002 - val_accuracy: 0.7481 - 16s/epoch - 785ms/step\n",
      "Epoch 13/20\n",
      "21/21 - 16s - loss: 0.0695 - accuracy: 0.9812 - val_loss: 1.4273 - val_accuracy: 0.7669 - 16s/epoch - 763ms/step\n",
      "Epoch 14/20\n",
      "21/21 - 16s - loss: 0.0737 - accuracy: 0.9821 - val_loss: 1.3828 - val_accuracy: 0.7820 - 16s/epoch - 770ms/step\n",
      "Epoch 15/20\n",
      "21/21 - 16s - loss: 0.0533 - accuracy: 0.9859 - val_loss: 1.4852 - val_accuracy: 0.7707 - 16s/epoch - 759ms/step\n",
      "Epoch 16/20\n",
      "21/21 - 16s - loss: 0.0659 - accuracy: 0.9821 - val_loss: 1.4035 - val_accuracy: 0.7895 - 16s/epoch - 770ms/step\n",
      "Epoch 17/20\n",
      "21/21 - 16s - loss: 0.0475 - accuracy: 0.9840 - val_loss: 1.5034 - val_accuracy: 0.7594 - 16s/epoch - 768ms/step\n",
      "Epoch 18/20\n",
      "21/21 - 16s - loss: 0.0227 - accuracy: 0.9944 - val_loss: 1.5664 - val_accuracy: 0.7632 - 16s/epoch - 759ms/step\n",
      "Epoch 19/20\n",
      "21/21 - 17s - loss: 0.0483 - accuracy: 0.9878 - val_loss: 1.4822 - val_accuracy: 0.8008 - 17s/epoch - 790ms/step\n",
      "Epoch 20/20\n",
      "21/21 - 16s - loss: 0.0386 - accuracy: 0.9878 - val_loss: 1.5220 - val_accuracy: 0.7857 - 16s/epoch - 783ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(tokenized_X_train, y_trainmatrix,\n",
    "          batch_size=51, epochs=20,\n",
    "          validation_data=(tokenized_X_val, y_valmatrix),\n",
    "          verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:12:53.549188459Z",
     "start_time": "2023-06-04T12:07:32.423676767Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "model.save('models/multy/LSTM/lstmemotionsmodel.h5')\n",
    "with open('tokenizers/multy/LSTM/lstmemotionstokenizer.pickle', 'wb') as handle:\n",
    "    p.dump(tokenizer, handle, protocol=p.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:12:53.647249010Z",
     "start_time": "2023-06-04T12:12:53.521877620Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "## данные в базе леманатизированы\n",
    "class CommonPreprocessing:\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_text(cls, text):\n",
    "#\n",
    "#\n",
    "        try:\n",
    "            tokens = str(text)\n",
    "            tokens = Mystem().lemmatize(text.lower())\n",
    "            tokens = [token for token in tokens if token not in stopwords.words('russian')\n",
    "                      and token != ' '\n",
    "                      and token.strip() not in punctuation]\n",
    "            tokens = [\n",
    "                token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "            text = ' '.join(tokens).rstrip('\\n')\n",
    "            pattern3 = r'[\\d]'\n",
    "            pattern2 = '[.]'\n",
    "            text = re.sub(pattern3, '', text)\n",
    "            text = re.sub(pattern2, '', text)\n",
    "            text = re.sub('  ', ' ', text)\n",
    "            return text\n",
    "        except:\n",
    "            return 'The exception is in CommonPreprocessing.preprocess_text'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:12:54.122955482Z",
     "start_time": "2023-06-04T12:12:53.640298587Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def predict(inpt, tmap, model, tokenizer):\n",
    "#\n",
    "#\n",
    "    try:\n",
    "        model = load_model(model)\n",
    "        inn = []\n",
    "        pr = CommonPreprocessing()\n",
    "        for i in inpt:\n",
    "            inn.append(pr.preprocess_text(i))\n",
    "\n",
    "        with open(tokenizer, 'rb') as handle:\n",
    "            tokenizer = p.load(handle)\n",
    "            tokenized_inpt = tokenizer.vectorize_input(inn)\n",
    "\n",
    "        scoreplu = model.predict(tokenized_inpt)\n",
    "        outpt = tmap[scoreplu.argmax(axis=-1)[0]]\n",
    "        return outpt\n",
    "    except:\n",
    "        return 'The exeption is in MultyLSTM.predict'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:12:54.131241976Z",
     "start_time": "2023-06-04T12:12:54.123667046Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "EMOTIONSMAPA = {0: '😞', 1: '🤬', 2: '😨', 3: '😊', 4: '❤', 5: '😳', 6: ''}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:12:54.139016776Z",
     "start_time": "2023-06-04T12:12:54.130069621Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "'🤬'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelpath = 'models/multy/LSTM/lstmemotionsmodel.h5'\n",
    "tokenizerpath = 'tokenizers/multy/LSTM/lstmemotionstokenizer.pickle'\n",
    "emotion = predict('привет',EMOTIONSMAPA, wmodelpath, tokenizerpath)\n",
    "emotion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:13:00.972841746Z",
     "start_time": "2023-06-04T12:12:54.137103709Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "w"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-04T12:13:00.982580997Z",
     "start_time": "2023-06-04T12:13:00.973817314Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
