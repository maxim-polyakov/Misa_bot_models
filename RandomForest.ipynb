{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:34.067959587Z",
     "start_time": "2023-06-03T20:57:27.092960025Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-03 23:57:29.762820: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-03 23:57:29.851366: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-03 23:57:29.853133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-03 23:57:31.983298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import psycopg2\n",
    "import pickle as p\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer as token\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "EMBEDDING_VECTOR_LENGTH = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    TOP_K = 20000\n",
    "    MAX_SEQUENCE_LENGTH = 33\n",
    "\n",
    "    def __init__(self, train_texts):\n",
    "        # токенизатор собственно\n",
    "        #\n",
    "        self.train_texts = train_texts\n",
    "        self.tokenizer = token(num_words=self.TOP_K)\n",
    "\n",
    "    def train_tokenize(self):\n",
    "        #\n",
    "        #\n",
    "        max_length = len(max(self.train_texts, key=len))\n",
    "        self.max_length = min(max_length, self.MAX_SEQUENCE_LENGTH)\n",
    "        self.tokenizer.fit_on_texts(self.train_texts)\n",
    "\n",
    "    def vectorize_input(self, tweets):\n",
    "        #\n",
    "        #\n",
    "        tweets = self.tokenizer.texts_to_sequences(tweets)\n",
    "        tweets = pad_sequences(tweets, maxlen=self.max_length, truncating='post', padding='post')\n",
    "        return tweets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:34.104705399Z",
     "start_time": "2023-06-03T20:57:34.079537392Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "SELECT_EMOTIONS = str('(select text, emotionid  FROM train_sets.all_set_weather ORDER BY random() LIMIT 3000) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_none ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_thanks ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_hi ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_business ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_trash ORDER BY random() LIMIT 600) ')\n",
    "\n",
    "conn_remote = psycopg2.connect(\n",
    "    'postgres://postgres:gaTResKPJX25@ep-round-paper-091468.us-east-2.aws.neon.tech/SistersMemory')\n",
    "\n",
    "target = 'emotionid'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:35.189890252Z",
     "start_time": "2023-06-03T20:57:34.097780216Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13281/178288445.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0       пасмурно время ливень температура давлениевете...\n1                                               прохладно\n2       помощь botfather создавать новый бот telegram ...\n3       малооблачный осадки температура давлениеветер ...\n4                                               прохладно\n                              ...                        \n5712                                           пердельник\n5713                       блять твой рот ебать приезжать\n5714                                      слышь хуесосина\n5715                              хотеть выебывать просто\n5716                             хуй рот засовывать блять\nName: text, Length: 5717, dtype: object"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n",
    "train.text = train.text.astype(str)\n",
    "train.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:37.482900201Z",
     "start_time": "2023-06-03T20:57:35.196490141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  emotionid\n",
      "0     пасмурно время ливень температура давлениевете...          6\n",
      "1                                             прохладно          6\n",
      "2     помощь botfather создавать новый бот telegram ...          6\n",
      "3     малооблачный осадки температура давлениеветер ...          6\n",
      "7     пасмурно небольшой снег температура давлениеве...          6\n",
      "...                                                 ...        ...\n",
      "5703                                        мразь гнида          1\n",
      "5706                     баня чайный ложка прикрываться          1\n",
      "5707                                              мудак          1\n",
      "5708  злить труп прятать некуда ладно шутить шутить ...          1\n",
      "5714                                    слышь хуесосина          1\n",
      "\n",
      "[1345 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train])\n",
    "train = df[~df[target].isna()]\n",
    "train[target] = train[target].astype(int)\n",
    "train = train.drop_duplicates()\n",
    "print(train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:37.543030902Z",
     "start_time": "2023-06-03T20:57:37.490764476Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train (941, 2)\n",
      "Shape of Validation  (404, 2)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(train, train[target], test_size=0.3, random_state=32)\n",
    "print('Shape of train', X_train.shape)\n",
    "print('Shape of Validation ', X_val.shape)\n",
    "tokenizer = Tokenizer(train_texts=X_train['text'])\n",
    "tokenizer.train_tokenize()\n",
    "tokenized_X_train = tokenizer.vectorize_input(X_train['text'])\n",
    "rfc = RandomForestClassifier(criterion='entropy', n_estimators=700)\n",
    "rfc.fit(tokenized_X_train, Y_train)\n",
    "with open('tokenizers/multy/RandomForest/0_rfemotionstokenizer.pickle', 'wb') as handle:\n",
    "    p.dump(tokenizer, handle, protocol=p.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('models/multy/RandomForest/0_rfemotionsmodel.pickle','wb') as handle:\n",
    "    p.dump(rfc, handle, protocol=p.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:42.489087823Z",
     "start_time": "2023-06-03T20:57:37.564201616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "## данные в базе леманатизированы\n",
    "class CommonPreprocessing:\n",
    "\n",
    "    @classmethod\n",
    "    def preprocess_text(cls, text):\n",
    "        # предобработчик приводит слова в начальную форму. Данные в базе находятся в леманатированном состоянии перед подачей на токенизацию в предикт слово тоже леманатируется\n",
    "        #\n",
    "        try:\n",
    "            tokens = str(text)\n",
    "            tokens = Mystem().lemmatize(text.lower())\n",
    "            tokens = [token for token in tokens if token not in stopwords.words('russian')\n",
    "                      and token != ' '\n",
    "                      and token.strip() not in punctuation]\n",
    "            tokens = [\n",
    "                token for token in tokens if token not in stopwords.words('english')]\n",
    "\n",
    "            text = ' '.join(tokens).rstrip('\\n')\n",
    "            pattern3 = r'[\\d]'\n",
    "            pattern2 = '[.]'\n",
    "            text = re.sub(pattern3, '', text)\n",
    "            text = re.sub(pattern2, '', text)\n",
    "            text = re.sub('  ', ' ', text)\n",
    "            return text\n",
    "        except:\n",
    "            return 'The exception is in CommonPreprocessing.preprocess_text'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:43.177277621Z",
     "start_time": "2023-06-03T20:57:42.497474173Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "\n",
    "    @classmethod\n",
    "    def predict(cls, inpt, tmap, model, tokenizer):\n",
    "        #\n",
    "        #\n",
    "            with open(model, 'rb') as handle:\n",
    "                model = p.load(handle)\n",
    "            inn = []\n",
    "            pr = CommonPreprocessing()\n",
    "            for i in inpt:\n",
    "                inn.append(pr.preprocess_text(i))\n",
    "\n",
    "            with open(tokenizer, 'rb') as handle:\n",
    "                tokenizer = p.load(handle)\n",
    "            x_val = tokenizer.vectorize_input(inn)\n",
    "            val_pred = model.predict(x_val)\n",
    "            return(tmap[val_pred[0]])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:43.236931843Z",
     "start_time": "2023-06-03T20:57:43.176730871Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "EMOTIONSMAPA = {0: '😞', 1: '🤬', 2: '😨', 3: '😊', 4: '❤', 5: '😳', 6: ''}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:43.257203943Z",
     "start_time": "2023-06-03T20:57:43.241912268Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'😨'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForest()\n",
    "modelpath = 'models/multy/RandomForest/0_rfemotionsmodel.pickle'\n",
    "tokenizerpath = 'tokenizers/multy/RandomForest/0_rfemotionstokenizer.pickle'\n",
    "emotion = rf.predict('привет',EMOTIONSMAPA, modelpath, tokenizerpath)\n",
    "emotion"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:52.997293199Z",
     "start_time": "2023-06-03T20:57:43.262107720Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T20:57:53.006046228Z",
     "start_time": "2023-06-03T20:57:53.001832918Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
