{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:09:57.179543124Z",
     "start_time": "2023-06-03T21:09:57.097858463Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle as p\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    TOP_K = 20000\n",
    "    MAX_SEQUENCE_LENGTH = 33\n",
    "\n",
    "    def __init__(self, train_texts):\n",
    "        # токенизатор собственно\n",
    "        #\n",
    "        self.train_texts = train_texts\n",
    "        self.tokenizer = token(num_words=self.TOP_K)\n",
    "\n",
    "    def train_tokenize(self):\n",
    "        #\n",
    "        #\n",
    "        max_length = len(max(self.train_texts, key=len))\n",
    "        self.max_length = min(max_length, self.MAX_SEQUENCE_LENGTH)\n",
    "        self.tokenizer.fit_on_texts(self.train_texts)\n",
    "\n",
    "    def vectorize_input(self, tweets):\n",
    "        #\n",
    "        #\n",
    "        tweets = self.tokenizer.texts_to_sequences(tweets)\n",
    "        tweets = pad_sequences(tweets, maxlen=self.max_length, truncating='post', padding='post')\n",
    "        return tweets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:09:58.258953870Z",
     "start_time": "2023-06-03T21:09:58.217703233Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "SELECT_EMOTIONS = str('(select text, emotionid  FROM train_sets.all_set_weather ORDER BY random() LIMIT 3000) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_none ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_thanks ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid FROM train_sets.all_set_hi ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_business ORDER BY random() LIMIT 600) ' +\n",
    "                      'union all ' +\n",
    "                      '(select text, emotionid  FROM train_sets.all_set_trash ORDER BY random() LIMIT 600) ')\n",
    "\n",
    "conn_remote = psycopg2.connect(\n",
    "    'postgres://postgres:gaTResKPJX25@ep-round-paper-091468.us-east-2.aws.neon.tech/SistersMemory')\n",
    "\n",
    "target = 'emotionid'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:10:00.058366060Z",
     "start_time": "2023-06-03T21:09:58.978090619Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13929/178288445.py:1: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n"
     ]
    },
    {
     "data": {
      "text/plain": "0                                             чистый небо\n1                                               прохладно\n2                                               прохладно\n3       облачно возможный гроза температура давлениеве...\n4       плохой погода бывать бывать неподходящий костю...\n                              ...                        \n5712                             хуй рот засовывать блять\n5713                                         ващ охуевать\n5714                                               дрочка\n5715                                               задрот\n5716                         приключение искать свой жопа\nName: text, Length: 5717, dtype: object"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_sql(SELECT_EMOTIONS, conn_remote)\n",
    "train.text = train.text.astype(str)\n",
    "train.text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:12:56.961065543Z",
     "start_time": "2023-06-03T21:12:55.963252932Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text  emotionid\n",
      "0                                           чистый небо          6\n",
      "1                                             прохладно          6\n",
      "3     облачно возможный гроза температура давлениеве...          6\n",
      "4     плохой погода бывать бывать неподходящий костю...          6\n",
      "5     становиться богатый знаменитый влиятельный — р...          6\n",
      "...                                                 ...        ...\n",
      "5704                           рот открывать стоматолог          1\n",
      "5705                                    слышь хуесосина          1\n",
      "5707                                   ебать заваль бля          1\n",
      "5713                                       ващ охуевать          1\n",
      "5714                                             дрочка          1\n",
      "\n",
      "[1309 rows x 2 columns]\n",
      "Shape of train (916, 2)\n",
      "Shape of Validation  (393, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train])\n",
    "train = df[~df[target].isna()]\n",
    "train[target] = train[target].astype(int)\n",
    "train = train.drop_duplicates()\n",
    "\n",
    "print(train)\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train, train[target], test_size=0.3,\n",
    "                                                  random_state=64)\n",
    "print('Shape of train', X_train.shape)\n",
    "print('Shape of Validation ', X_val.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:14:34.015801116Z",
     "start_time": "2023-06-03T21:14:33.985246097Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(train_texts=X_train['text'])\n",
    "\n",
    "tokenizer.train_tokenize()\n",
    "tokenized_X_train = tokenizer.vectorize_input(X_train['text'])\n",
    "tokenized_X_val = tokenizer.vectorize_input(X_val['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:14:34.686668532Z",
     "start_time": "2023-06-03T21:14:34.649034481Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "model_xgboost = xgboost.XGBClassifier(learning_rate=0.1,\n",
    "                                      max_depth=10,\n",
    "                                      n_estimators=500,\n",
    "                                      subsample=0.5,\n",
    "                                      colsample_bytree=0.5,\n",
    "                                      eval_metric='auc',\n",
    "                                      verbosity=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:14:35.624304668Z",
     "start_time": "2023-06-03T21:14:35.571656555Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m eval_set \u001B[38;5;241m=\u001B[39m [(tokenized_X_val, Y_val)]\n\u001B[0;32m----> 3\u001B[0m \u001B[43mmodel_xgboost\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtokenized_X_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mY_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                  \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_set\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/core.py:620\u001B[0m, in \u001B[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k, arg \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters, args):\n\u001B[1;32m    619\u001B[0m     kwargs[k] \u001B[38;5;241m=\u001B[39m arg\n\u001B[0;32m--> 620\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1440\u001B[0m, in \u001B[0;36mXGBClassifier.fit\u001B[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001B[0m\n\u001B[1;32m   1435\u001B[0m     expected_classes \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marange(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_classes_)\n\u001B[1;32m   1436\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1437\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;241m!=\u001B[39m expected_classes\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m   1438\u001B[0m     \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m==\u001B[39m expected_classes)\u001B[38;5;241m.\u001B[39mall()\n\u001B[1;32m   1439\u001B[0m ):\n\u001B[0;32m-> 1440\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1441\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid classes inferred from unique values of `y`.  \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1442\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_classes\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1443\u001B[0m     )\n\u001B[1;32m   1445\u001B[0m params \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_xgb_params()\n\u001B[1;32m   1447\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callable(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobjective):\n",
      "\u001B[0;31mValueError\u001B[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2 3 4 5], got [1 2 3 4 5 6]"
     ]
    }
   ],
   "source": [
    "eval_set = [(tokenized_X_val, Y_val)]\n",
    "\n",
    "model_xgboost.fit(tokenized_X_train,\n",
    "                  Y_train,\n",
    "                  early_stopping_rounds=100,\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:16:51.512474420Z",
     "start_time": "2023-06-03T21:16:51.456654777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "with open('tokenizer', 'wb') as handle:\n",
    "    p.dump(tokenizer, handle, protocol=p.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('model', 'wb') as handle:\n",
    "    p.dump(model_xgboost, handle, protocol=p.HIGHEST_PROTOCOL)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-03T21:14:42.875414929Z",
     "start_time": "2023-06-03T21:14:42.847807040Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
